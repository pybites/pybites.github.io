<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="Table of Contents Cleaning Text Data with Python Tokenisation Normalising Case Remove All Punctuation Stop Words Spelling and Repeated Characters (Word Standardisation) Remove URLs, Email...">
        <meta name="keywords" content="case, email, guest, lemmatisation, punctuation, spelling, stemming, stop words, tokenisation, urls">
        <link rel="icon" href="https://pybit.es/favicon.ico">

        <title>Cleaning Text Data With Python - PyBites</title>

        <!-- Stylesheets -->
        <link href="https://pybit.es/theme/css/all.min.css" rel="stylesheet">
        <link href="https://pybit.es/theme/css/style.css" rel="stylesheet">
        <!-- /Stylesheets -->

        <!-- RSS Feeds -->
        <link href="https://pybit.es/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="PyBites Full Atom Feed" />
        <link href="https://pybit.es/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="PyBites Full RSS Feed" />
        <link href="https://pybit.es/feeds/data-science.rss.xml" type="application/rss+xml" rel="alternate" title="PyBites Categories RSS Feed" />
        <!-- /RSS Feeds -->

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->

          <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5859c6a67eb6254d" async="async"></script>

        <!-- Google Analytics -->
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-89294245-1', 'auto');
          ga('send', 'pageview');
        </script>
        <!-- /Google Analytics -->



    <!-- mailchimp subscribe -->
    <script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us14.list-manage.com","uuid":"822043293f280259d4b8d2a3e","lid":"ac7e2eb9ef","uniqueMethods":true}) })</script>
    <!-- end mailchimp subscribe -->

    <!-- Facebook Pixel Code -->
    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window, document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '767652523960315');
    fbq('track', 'PageView');
    </script>
    <noscript><img height="1" width="1" style="display:none"
    src="https://www.facebook.com/tr?id=767652523960315&ev=PageView&noscript=1"
    /></noscript>
    <!-- End Facebook Pixel Code -->

    </head>

    <body>

        <!-- Header -->
    <div class="header-container gradient">

            <!-- Static navbar -->
            <div class="container">
                <div class="header-nav">
                    <div class="header-logo">
                        <a class="pull-left" href="https://pybit.es/"><img class="mr20" src="https://pybit.es/images/logo.png" alt="logo"></a>
                    </div>
                    <div class="nav pull-right">

                        <div class="dropdown">
                          <span>RESOURCES</span>
                          <div class="dropdown-content">
                                <a href="https://www.pybitespodcast.com"
                                    target="_blank"
                                >PyBites Podcast</a>
                                <a href="/friends"
                                >PyBites Friends</a>
                                <a href="/community"
                                >PyBites Community</a>
                                <a href="/archives"
                                >PyBites Articles</a>
                                <a href="https://github.com/PyBites-Open-Source"
                                    target="_blank"
                                >PyBites Open Source</a>
                                <a href="https://www.udemy.com/course/python-flask-for-beginners/"
                                    target="_blank"
                                >Flask Intro Course</a>
                                <a href="/category/challenges"
                                >Blog Challenges</a>
                          </div>
                        </div>

                        <div class="dropdown">
                          <span>SERVICES</span>
                          <div class="dropdown-content">
                                <a href="https://codechalleng.es"
                                    target="_blank"
                                >Python CodeChalleng.es</a>
                                <a href="https://members.pybit.es/offers/mfFWRKHG/checkout"
                                    target="_blank"
                                >Python Intro Course</a>
                                <a href="/pages/schools"
                                >Teach Python to Kids</a>
                                <a href="/pages/enterprise"
                                >Use PyBites at Work</a>
                                <a href="/pages/recruiting"
                                >Recruit Python Talent</a>
                                <a href="/100days"
                                >100 Days of Code Courses</a>
                                <a href="/apply"
                                >Work With Us</a>
                          </div>
                        </div>

                        <div class="dropdown">
                          <a href="https://gumroad.com/l/pbtips" id="workshopButton">Python Tips Book</a>
                        </div>

                    </div>
                </div>
            </div>
            <!-- /Static navbar -->

            <!-- Header -->
    <!-- Header -->
    <div class="container header-wrapper">
        <div class="row">
              <div class="col-lg-12">
                  <div class="header-content">
                      <h1 class="header-title">Cleaning Text Data With Python</h1>
                      <p class="header-date"> <a href="https://pybit.es/author/david-colton.html">David Colton</a>, Wed 30 September 2020,  <a href="https://pybit.es/category/data-science.html">Data science</a></p>
                      <div class="header-underline"></div>
                      <div class="clearfix"></div>
                      <p class="pull-right header-tags">
                          <span class="glyphicon glyphicon-tags mr5" aria-hidden="true"></span>
<a href="https://pybit.es/tag/case.html">case</a>, <a href="https://pybit.es/tag/email.html">email</a>, <a href="https://pybit.es/tag/guest.html">guest</a>, <a href="https://pybit.es/tag/lemmatisation.html">lemmatisation</a>, <a href="https://pybit.es/tag/punctuation.html">punctuation</a>, <a href="https://pybit.es/tag/spelling.html">spelling</a>, <a href="https://pybit.es/tag/stemming.html">stemming</a>, <a href="https://pybit.es/tag/stop-words.html">stop words</a>, <a href="https://pybit.es/tag/tokenisation.html">tokenisation</a>, <a href="https://pybit.es/tag/urls.html">urls</a>                      </p>
                  </div>
              </div>
        </div>
    </div>
    <!-- /Header -->
            <!-- /Header -->

        </div>
        <!-- /Header -->


        <!-- Content -->
    <div class="container content">
        <h1>Table of Contents</h1>
<ol>
<li><a href="#cleaning-text">Cleaning Text Data with Python</a></li>
<li><a href="#tokenisation">Tokenisation</a></li>
<li><a href="#normalising-case">Normalising Case</a></li>
<li><a href="#remove-punctuation">Remove All Punctuation</a></li>
<li><a href="#stop-words">Stop Words</a></li>
<li><a href="#word-standardisation">Spelling and Repeated Characters (Word Standardisation)</a></li>
<li><a href="#remove">Remove URLs, Email Addresses and Emojis</a></li>
<li><a href="#stemming-lemmatisation">Stemming and Lemmatisation</a></li>
<li><a href="#demonstration">A Simple Demonstration</a></li>
</ol>
<p><a name="cleaning-text"></a></p>
<h1>Cleaning Text Data with Python</h1>
<p>Machine Learning is super powerful if your data is numeric. What do you do, however, if you want to mine text data to discover hidden insights or to predict the sentiment of the text. What, for example, if you wanted to identify a post on a social media site as cyber bullying. </p>
<p>The first concept to be aware of is a Bag of Words. When training a model or classifier to identify documents of different types a bag of words approach is a commonly used, but basic, method to help determine a document's class. A bag of words is a representation of text as a set of independent words with no relationship to each other. It is called a “<em>bag</em>” of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.  It involves two things:</p>
<ol>
<li>A vocabulary of known words.</li>
<li>A measure of the presence of known words.</li>
</ol>
<p>Consider the phrases </p>
<ul>
<li>"<em>The cat in the hat sat in the window</em>"</li>
<li>"<em>The dog sat on the hat</em>"</li>
</ul>
<p>These phrases can be broken down into the following vector representations with a simple measure of the count of the number of times each word appears in the document (phrase):</p>
<table>
<thead>
<tr>
<th>Word</th>
<th>the</th>
<th>cat</th>
<th>dog</th>
<th>in</th>
<th>on</th>
<th>hat</th>
<th>sat</th>
<th>window</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Phrase 1</strong></td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td><strong>Phrase 2</strong></td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>These two vectors <code>[3, 1, 0, 2, 0, 1, 1, 1]</code> and <code>[2, 0, 1, 0, 1, 1, 1, 0]</code> could now be be used as input into your data mining model.</p>
<p>A more sophisticated way to analyse text is to use a measure called Term Frequency - Inverse Document Frequency (TF-IDF). Term Frequency (TF) is the number of times a word appears in a document. This means that the more times a word appears in a document the larger its value for TF will get. The TF weighting of a word in a document shows its importance within that single document. Inverse Document Frequency (IDF) then shows the importance of a word within the entire collection of documents or corpus. The nature of the IDF value is such that terms which appear in a lot of documents will have a lower score or weight. This means terms that only appear in a single document, or in a small percentage of the documents, will receive a higher score. This higher score makes that word a good discriminator between documents. The TF-IDF weight for a word <code>i</code> in document <code>j</code> is given as:</p>
<p><img alt="TF-IDF weight image" src="https://pybit.es/images/TFIDFij.png"></p>
<p>A detailed background and explanation of TF-IDF, including some Python examples, is given here <a href="https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf">Analyzing Documents with TF-IDF</a>. Suffice it to say that TF-IDF will assign a value to every word in every document you want to analyse and, the higher the TF-IDF value, the more important or predictive the word will typically be.</p>
<p>However, before you can use TF-IDF you need to clean up your text data. But why do we need to clean text, can we not just eat it straight out of the tin? The answer is yes, if you want to, you can use the raw data exactly as you've received it, however, cleaning your data will increase the accuracy of your model. This guide is a very basic introduction to some of the approaches used in cleaning text data. Some techniques are simple, some more advanced. For the more advanced concepts, consider their inclusion here as pointers for further personal research. </p>
<p>In the following sections I'm assuming that you have plain text and your text is not embedded in HTML or Markdown or anything like that. If your data is embedded in HTML, for example, you could look at using a package like <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> to get access to the raw text before proceeding. You could use <a href="https://pypi.org/project/Markdown/">Markdown</a> if your text is stored in Markdown.</p>
<p><a name="tokenisation"></a></p>
<h2>Tokenisation</h2>
<p>Typically the first thing to do is to tokenise the text. This is just a fancy way of saying split the data into individual words that can be processed separately. Tokenisation is also usually as simple as splitting the text on white-space. It's important to know how you want to represent your text when it is dived into blocks. By this I mean are you tokenising and grouping together all words on a line, in a sentence, all words in a paragraph or all words in a document. The simplest assumption is that each line a file represents a group of tokens but you need to verify this assumption. BTW I said you should do this first, I lied. A lot of the tutorials, sample code on the internet talks about tokenising your text immediately. This then has the downside that some of the simpler clean up tasks, like converting to lowercase and removing punctuation for example, need to be applied to each token and not on the text block as a whole. Something to consider.</p>
<p><a name="normalising-case"></a></p>
<h2>Normalising Case</h2>
<p>This is just a fancy way of saying convert all your text to lowercase. If using Tf-IDF <code>Hello</code> and <code>hello</code> are two different tokens. This has the side effect of reducing the total size of the vocabulary, or corpus, and some knowledge will be lost such as Apple the company versus eating an apple. In all cases you should consider if each of these actions actually make sense to the text analysis you are performing. If you are not sure, or you want to see the impact of a particular cleaning technique try the before and after text to see which approach gives you a more predictive model. Sometimes, in text mining, there are multiple different ways of achieving one's goal, and this is not limited to text mining as it is the same for standardisation in normal Machine Learning.</p>
<p><a name="remove-punctuation"></a></p>
<h2>Remove Punctuation</h2>
<p>When a bag of words approach, like described above is used, punctuation can be removed as sentence structure and word order is irrelevant when using TF-IDF.  Some words of caution though. Punctuation can be vital when doing sentiment analysis or other NLP tasks so understand your requirements. Also, if you are also going to remove URL's and Email addresses you might want to the do that before removing punctuation characters otherwise they'll be a bit hard to identify. Another consideration is hashtags which you might want to keep so you may need a rule to remove <code>#</code> unless it is the first character of the token.</p>
<p><a name="stop-words"></a></p>
<h2>Stop Words</h2>
<p><a href="https://en.wikipedia.org/wiki/Stop_word">Stop Words</a> are the most commonly used words in a language. You could consider them the glue that binds the important words into a sentence together. Sample stop words are <code>I, me, you, is, are, was</code> etc. Removing stop words have the advantage of reducing the size of your corpus and your model will also train faster which is great for tasks like Classification or Spam Filtering. Removing stop words also has the advantage of reducing the noise signal ratio as we don't want to analyse stop words because they are very unlikely to contribute to the classification task. However, another word or warning. If you are doing sentiment analysis consider these two sentences:</p>
<ul>
<li><em>this movie was not good</em></li>
<li><em>movie good</em></li>
</ul>
<p>By removing stop words you've changed the sentiment of the sentence. Who said NLP and Text Mining was easy.</p>
<p><a name="word-standardisation"></a></p>
<h2>Spelling and Repeated Characters (Word Standardisation)</h2>
<p>Fixing obvious spelling errors can both increase the predictiveness of your model and speed up processing by reducing the size of your corpora. A good example of this is on Social Media sites when words are either truncated, deliberately misspelt or accentuated by adding unnecessary repeated characters. Consider:</p>
<ul>
<li><code>love, luv, lovvvvv, lovvveeee</code></li>
</ul>
<p>To an English speaker it's pretty obvious that the single word that represents all these tokens is <code>love</code>. Standardising your text in this manner has the potential to improve the predictiveness of your model significantly. </p>
<p><a name="remove"></a></p>
<h2>Remove URLs, Email Addresses and Emojis</h2>
<p>Depending on your modelling requirements you might want to either leave these items in your text or further preprocess them as required. A general approach though is to assume these are not required and should be excluded. Consider if it is worth converting your emojis to text, would this bring extra predictiveness to your model? Regular expressions are the go to solution for removing URLs and email addresses.</p>
<p><a name="stemming-lemmatisation"></a></p>
<h2>Stemming and Lemmatisation</h2>
<p>Stemming is a process by which derived or inflected words are reduced to their stem, sometimes also called the base or root. Using the words <code>stemming</code> and <code>stemmed</code> as examples, these are both based on the word <code>stem</code>. <strong>Stemming</strong> algorithms work by cutting off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found in an inflected word.</p>
<p><strong>Lemmatisation</strong> in linguistics, is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. In languages, words can appear in several inflected forms. For example, in English, the verb 'to walk' may appear as 'walk', 'walked', 'walks', 'walking'. The base form, 'walk', that one might look up in a dictionary, is called the lemma for the word.</p>
<p>So stemming uses <em>predefined rules</em> to transform the word into a <em>stem</em> whereas lemmatisation uses <em>context</em> and <em>lexical library</em> to derive a <em>lemma</em>. The <em>stem</em> doesn’t always have to be a valid word whereas <em>lemma</em> will always be a valid word because <em>lemma</em> is a dictionary form of a word.</p>
<p><a name="demonstration"></a></p>
<h2>A Simple Demonstration</h2>
<p>Let have a look at some simple examples. We start by creating a string with five lines of text:</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">data</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;This is the first line</span>
<span class="s2">    ...: This is the 2nd line</span>
<span class="s2">    ...: The third line, this line, has punctuation.</span>
<span class="s2">    ...: THE FORTH LINE I we and you are not wanted</span>
<span class="s2">    ...: I lovveee email fred@flintsones.ie&quot;&quot;&quot;</span>
</pre></div>


<p>At this point we could split the text into lines and split lines into tokens but first lets covert all the text to lowercase (line 4), remove that email address (line 5) and punctuation (line 6) and then split the string into lines (line 7).</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="kn">import</span> <span class="nn">re</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="kn">import</span> <span class="nn">string</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="n">data</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\S*@\S*\s*&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">6</span><span class="p">]:</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">))</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">7</span><span class="p">]:</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">8</span><span class="p">]:</span> <span class="n">lines</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">8</span><span class="p">]:</span>
<span class="p">[</span><span class="s1">&#39;this is the first line&#39;</span><span class="p">,</span>
 <span class="s1">&#39;this is the 2nd line&#39;</span><span class="p">,</span>
 <span class="s1">&#39;the third line this line has punctuation&#39;</span><span class="p">,</span>
 <span class="s1">&#39;the forth line i we and you are not wanted&#39;</span><span class="p">,</span>
 <span class="s1">&#39;i lovveee email rocks&#39;</span><span class="p">]</span>
</pre></div>


<p>Line 8 now shows the contents of the data variable which is now a list of 5 strings).</p>
<p>Next we'll tokenise each sentence and remove stop words. Normally you's use something like NLTK (Natural Language Toolkit) to remove stop words but in this case we'll just use a list of prepared tokens (words)</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">9</span><span class="p">]:</span> <span class="n">tokens</span> <span class="o">=</span> <span class="p">[[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">10</span><span class="p">]:</span> <span class="n">tokens</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">10</span><span class="p">]:</span>
<span class="p">[[</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="s1">&#39;line&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;2nd&#39;</span><span class="p">,</span> <span class="s1">&#39;line&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;third&#39;</span><span class="p">,</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="s1">&#39;punctuation&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;forth&#39;</span><span class="p">,</span> <span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="s1">&#39;wanted&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;lovveee&#39;</span><span class="p">,</span> <span class="s1">&#39;email&#39;</span><span class="p">,</span> <span class="s1">&#39;rocks&#39;</span><span class="p">]]</span>
</pre></div>


<p>The final data cleansing example to look is spell checking and word normalisation. If we look at the list of tokens above you can see that there are two potential misspelling candidates <code>2nd</code> and <code>lovveee</code>. Rather then fixing them outright, as every text mining scenario is different a possible solution to help identify the misspelt words in your corpus is shown. This would then allow you determine the percentage of words that are misspelt and, after analysis or all misspellings or a sample if the number of tokens is very large, an appropriate substituting algorithm if required.</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">from</span> <span class="nn">spellchecker</span> <span class="kn">import</span> <span class="n">SpellChecker</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">spell</span> <span class="o">=</span> <span class="n">SpellChecker</span><span class="p">()</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">misspelled</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lovve&#39;</span><span class="p">,</span> <span class="s1">&#39;lovee&#39;</span><span class="p">,</span> <span class="s1">&#39;lovvee&#39;</span><span class="p">,</span> <span class="s1">&#39;lovveee&#39;</span><span class="p">,</span> <span class="s1">&#39;2nd&#39;</span><span class="p">]</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">misspelled</span><span class="p">:</span>
    <span class="o">...</span><span class="p">:</span>    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;{word}: </span><span class="se">\t</span><span class="s1">{spell.correction(word)} </span><span class="se">\t</span><span class="s1">{spell.candidates(word)}&#39;</span><span class="p">)</span>
    <span class="o">...</span><span class="p">:</span>
<span class="n">lovve</span><span class="p">:</span>    <span class="n">love</span>    <span class="p">{</span><span class="s1">&#39;love&#39;</span><span class="p">}</span>
<span class="n">lovee</span><span class="p">:</span>    <span class="n">love</span>    <span class="p">{</span><span class="s1">&#39;lover&#39;</span><span class="p">,</span> <span class="s1">&#39;love&#39;</span><span class="p">,</span> <span class="s1">&#39;levee&#39;</span><span class="p">,</span> <span class="s1">&#39;loved&#39;</span><span class="p">,</span> <span class="s1">&#39;lovey&#39;</span><span class="p">,</span> <span class="s1">&#39;loves&#39;</span><span class="p">}</span>
<span class="n">lovvee</span><span class="p">:</span>   <span class="n">love</span>    <span class="p">{</span><span class="s1">&#39;lover&#39;</span><span class="p">,</span> <span class="s1">&#39;lovage&#39;</span><span class="p">,</span> <span class="s1">&#39;ovver&#39;</span><span class="p">,</span> <span class="s1">&#39;love&#39;</span><span class="p">,</span> <span class="s1">&#39;levee&#39;</span><span class="p">,</span> <span class="o">...</span> <span class="s1">&#39;loves&#39;</span><span class="p">,</span> <span class="s1">&#39;loaves&#39;</span><span class="p">}</span>
<span class="n">lovveee</span><span class="p">:</span>    <span class="n">lovveee</span> <span class="p">{</span><span class="s1">&#39;lovveee&#39;</span><span class="p">}</span>
<span class="mi">2</span><span class="n">nd</span><span class="p">:</span>        <span class="ow">and</span>     <span class="p">{</span><span class="s1">&#39;mnd&#39;</span><span class="p">,</span> <span class="s1">&#39;und&#39;</span><span class="p">,</span> <span class="s1">&#39;ond&#39;</span><span class="p">,</span> <span class="s1">&#39;nd&#39;</span><span class="p">,</span> <span class="s1">&#39;cnd&#39;</span><span class="p">,</span> <span class="s1">&#39;ind&#39;</span><span class="p">,</span> <span class="s1">&#39;bnd&#39;</span><span class="p">,</span> <span class="s1">&#39;and&#39;</span><span class="p">,</span> <span class="s1">&#39;hnd&#39;</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">}</span>
</pre></div>


<p>In lines 1 and 2 a <a href="https://pypi.org/project/pyspellchecker/">Spell Checker</a> is imported and initialised. Line 3 creates a list of misspelt words. Then in line 4 each misspelt word, the corrected word, and possible correction candidate are printed. This is not suggested as an optimised solution but only provided as a suggestion.</p>
<p>Keep calm and code in Python!</p>
<p>-- <a href="pages/guests.html#davidcolton">David</a></p>


    <div class="comments">
        <div id="disqus_thread"></div>
            <script type="text/javascript">
                var disqus_shortname = 'http-pybit-es';
                var disqus_identifier = 'guest-clean-text-data.html';
                var disqus_url = 'https://pybit.es/guest-clean-text-data.html';
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
        <noscript>Please enable JavaScript to view the comments.</noscript>
    </div>
        
    </div>
        <!-- /Content --> 

        <!-- Footer -->
        <div class="footer gradient-2">
            <div class="container footer-container ">
                <div class="row">
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Sitemap</div>
                        <ul class="list-unstyled">
                            <li><a href="https://pybit.es/pages/guests.html">Authors</a></li>
                            <li><a href="https://pybit.es/pages/community.html">Community</a></li>
                            <li><a href="https://pybit.es/100days">#100DaysOfCode</a></li>
                            <li><a href="https://pybit.es/pages/search.html">Search</a></li>
                            <li><a href="https://pybit.es/pages/privacy-policy.html">Privacy Policy</a></li>
                              <li><a href="https://pybit.es/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">Atom Feed</a></li>
                              <li><a href="https://pybit.es/feeds/all.rss.xml" type="application/rss+xml" rel="alternate">RSS Feed</a></li>
                            <li><a href="mailto:support@pybit.es" title="Contact us by email">Contact Us</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Reach Out</div>
                        <ul class="list-unstyled">
                            <li><a href="mailto:support@pybit.es" target="_blank">Email</a></li>
                            <li><a href="https://twitter.com/pybites" target="_blank">Twitter</a></li>
                            <li><a href="https://facebook.com/pybites" target="_blank">Facebook</a></li>
                            <li><a href="https://github.com/pybites" target="_blank">Github</a></li>
                            <li><a href="https://github.com/PyBites-Open-Source" target="_blank">Open Source</a></li>
                            <li><a href="https://www.youtube.com/channel/UCBn-uKDGsRBfcB0lQeOB_gA" target="_blank">YouTube</a></li>
                        </ul>
                    </div> 
                    <div class="col-xs-12 col-sm-3 col-md-3 col-lg-3">
                        <p class="pull-right text-right">
                            <small><em>Proudly powered by <a href="http://docs.getpelican.com/" target="_blank">pelican</a></em></small><br/>
                            <small><em>Theme and code by <a href="https://github.com/molivier" target="_blank">molivier</a></em></small><br/>
                            <small>&copy; PyBites 2016+</small>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!-- /Footer -->
    </body>
</html>